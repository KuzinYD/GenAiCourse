from openai import OpenAI
from capstone_i.utils import get_logger
from capstone_i.utils import db_helper
from dotenv import find_dotenv
import os
import json

client = OpenAI()
env_file = find_dotenv()

logger = get_logger("ask_db tool")

DATABASE_URL = os.getenv('DATABASE_URL')
MODEL = "gpt-4"

database_schema = db_helper.get_database_schema()

tools = [
    {
        "type": "function",
        "name": "ask_database",
        "description": "Get an answer from the SQL database based on a query.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": f"""
                            SQL query extracting info to answer the user's question.
                            SQL should be written using this database schema:
                            {database_schema}
                            The query should be returned in plain text, not in JSON.
                            """,
                }
            },
            "required": ["query"],
        },
    },
]

messages = [
    {"role": "user", "content": "Give me 11 wines with the highest ratings."},
]

response = client.responses.create(
    model=MODEL,
    tools=tools,
    input=messages,
)

for item in response.output:
    if item.type == "function_call":
        if item.name == "ask_database":
            db_result = db_helper.ask_database(json.loads(item.arguments)["query"])
            messages.append({"role": "assistant", "content": str(db_result)})
logger.info("Messages: %s", messages)

response = client.responses.create(
    model=MODEL,
    instructions="Respond to initial user question with a database result generated by a tool. Use markdown formatting. Inform them that the results were limited to 10 rows.",
    input=messages
)

logger.info("Final output: " + response.output_text)